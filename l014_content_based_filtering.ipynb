{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f61cf600-304e-4188-a312-0608348a40f1",
   "metadata": {},
   "source": [
    "# Recommender Systems: Content-Based Filtering Notes\n",
    "\n",
    "Recommender systems help users discover items they are likely to appreciate. While collaborative filtering relies solely on user–item interactions, content-based filtering leverages detailed feature information to make more nuanced recommendations.\n",
    "\n",
    "- **Collaborative Filtering:**  \n",
    "  - Recommends items based on the ratings from similar users.\n",
    "  - Uses patterns in user ratings.\n",
    "  - Example: \"Users who liked item A also liked item B.\"\n",
    "  \n",
    "- **Content-Based Filtering:**\n",
    "  - Recommends items based on the features (attributes) of users and items.\n",
    "  - Uses features of users and items to compute a match.\n",
    "  - **Analogy:** Think of it as matching a customer’s unique taste profile (user features) with the characteristics of a product (item features).\n",
    "\n",
    "### Defining Feature Vectors\n",
    "\n",
    "For **users** and **movies** (items), we define:\n",
    "\n",
    "**User feature vector:** $x_u$  \n",
    "- Examples: Age, gender, country, past viewing history, and even aggregate statistics like the average rating by genre.\n",
    "  \n",
    "**Item feature vector:** $x_m$  \n",
    "- Examples: Year of release, genres, star cast, critic reviews, average ratings.\n",
    "  \n",
    "After processing, these raw features are transformed into compact vectors:\n",
    "- **User representation:** $v_u$\n",
    "- **Movie representation:** $v_m$\n",
    "\n",
    "The goal is that the dot product, $v_u \\cdot v_m$, approximates how much a user will enjoy a movie (or any item).\n",
    "\n",
    "---\n",
    "\n",
    "## Building the Content-Based Filtering Model\n",
    "\n",
    "### Feature Engineering\n",
    "\n",
    "**User features:**  \n",
    "- Demographics (age, gender, country) can be one-hot encoded.\n",
    "- Behavioral features can be constructed from viewing history (e.g., a thousand-dimensional vector indicating which popular movies the user has watched).\n",
    "- Aggregated ratings per genre provide insights into a user's taste.\n",
    "\n",
    "**Item features:**  \n",
    "- Attributes like the movie’s release year, genres, and even critic reviews.\n",
    "- You can also compute statistics (e.g., average rating, average rating per demographic) to enrich the feature set.\n",
    "\n",
    "### Neural Network Architecture\n",
    "\n",
    "The model uses two separate networks:\n",
    "\n",
    "**User Network:**  \n",
    "- **Input:** User feature vector $x_u$.\n",
    "- **Processing:** Several dense layers.\n",
    "- **Output:** A compact vector $v_u$ (e.g., 32-dimensional).\n",
    "\n",
    "**Movie (Item) Network:**  \n",
    "- **Input:** Movie feature vector $x_m$.\n",
    "- **Processing:** Similar dense layers.\n",
    "- **Output:** A compact vector $v_m$.\n",
    "\n",
    "Both networks output vectors of the same dimension so that their dot product is valid.\n",
    "\n",
    "> **Key Point:** The final prediction is computed as $\\\\hat{y}^{ij} = v_u^j \\\\cdot v_m^i$, where $\\\\hat{y}^{ij}$ approximates the rating that user $j$ would give to movie $i$.\n",
    "\n",
    "### Training the Model\n",
    "\n",
    "**Cost Function:**  \n",
    "- Mean squared error (MSE) is used to measure the difference between the predicted and actual ratings:\n",
    "  \n",
    "$$J = \\\\sum_{(i,j) \\\\in \\\\mathcal{D}} (v_u^j \\\\cdot v_m^i - y^{ij})^2.$$\n",
    "\n",
    "**Optimization:**  \n",
    "- Use gradient descent (or its variants) to adjust the parameters in both networks.\n",
    "- Regularization (e.g., L2 regularization) can be added to prevent overfitting.\n",
    "\n",
    "### Normalization\n",
    "- Both $v_u$ and $v_m$ are often normalized (using the L2 norm) so that their lengths are one. This helps in stabilizing the training and ensuring the dot product reflects a cosine similarity–like measure.\n",
    "\n",
    "---\n",
    "\n",
    "## Scalability: Retrieval and Ranking\n",
    "\n",
    "When dealing with very large catalogs (millions of items), computing the neural network output for every item is impractical. Modern systems adopt a two-step process:\n",
    "\n",
    "### Retrieval Step\n",
    "\n",
    "**Purpose:** Quickly generate a broad list of plausible candidates.\n",
    "\n",
    "**Method:**  \n",
    "- Use pre-computed similarity metrics. For example, for each movie, precompute the top similar movies.\n",
    "- Leverage simple heuristics (e.g., most viewed genres, regional popularity).\n",
    "  \n",
    "**Analogy:** Think of this as \"shortlisting\" candidates before the detailed interview.\n",
    "\n",
    "### 2. Ranking Step\n",
    "\n",
    "**Purpose:** Fine-tune and rank the candidate items accurately.\n",
    "\n",
    "**Method:**  \n",
    "- Use the neural network model to compute predictions for the shortlisted items.\n",
    "- Rank them based on the predicted rating or likelihood of engagement.\n",
    "  \n",
    "**Optimization:**  \n",
    "- If item vectors $v_m$ are precomputed, only the user vector $v_u$ needs to be computed in real time.\n",
    "- The dot product between $v_u$ and the precomputed $v_m$ values is used for fast scoring.\n",
    "\n",
    "---\n",
    "\n",
    "## Ethical Considerations\n",
    "\n",
    "Recommender systems, while profitable and efficient, carry potential risks. It is important to be aware of the following:\n",
    "\n",
    "### Transparency vs. Profit Maximization\n",
    "\n",
    "- **Issue:** Systems may prioritize high-profit items over those that best serve user interests.\n",
    "- **Example:** A website might rank products that generate more profit even if they are less relevant to the user.\n",
    "\n",
    "### Content and Engagement Risks\n",
    "\n",
    "**Maximizing Engagement:**  \n",
    "- Systems that optimize for watch time or clicks may inadvertently promote polarizing or harmful content (e.g., conspiracy theories, hate speech).\n",
    "\n",
    "**Mitigation:**  \n",
    "- Implement content filters and consider ethical guidelines.\n",
    "- Be transparent with users about recommendation criteria.\n",
    "\n",
    "### Social Impact\n",
    "\n",
    "**Exploitation in Advertising:**  \n",
    "- Models might amplify harmful practices (e.g., payday loans) if profit is the sole criterion.\n",
    "\n",
    "**Responsible Design:**  \n",
    "- Developers are encouraged to incorporate ethical safeguards and invite diverse perspectives to minimize harm.\n",
    "\n",
    "> **Ethical Reminder:** Always design recommender systems with the dual goal of user benefit and societal well-being. Transparency and fairness are key.\n",
    "\n",
    "---\n",
    "\n",
    "## TensorFlow Implementation: A Practical Walkthrough\n",
    "\n",
    "The final section covers a brief overview of how to implement content-based filtering in TensorFlow.\n",
    "\n",
    "### Model Definition\n",
    "\n",
    "**User Network:**  \n",
    "- Use a sequential model with several dense layers.\n",
    "- Final dense layer outputs a 32-dimensional vector $v_u$.\n",
    "  \n",
    "**Movie (Item) Network:**  \n",
    "- A similar sequential model that outputs a 32-dimensional vector $v_m$.\n",
    "\n",
    "### Data Flow and Layers\n",
    "\n",
    "- **Input Layers:** Extract user features and item features.\n",
    "- **Normalization:** Apply L2 normalization on $v_u$ and $v_m$ to enforce unit length.\n",
    "- **Dot Product Layer:** A special Keras layer computes the dot product between $v_u$ and $v_m$, yielding the final prediction.\n",
    "\n",
    "### Cost Function and Training\n",
    "\n",
    "- **Loss:** Use mean squared error (MSE) for regression tasks or apply a sigmoid function with binary cross-entropy for classification (e.g., predicting clicks).\n",
    "- **Training:** Train the combined model (both networks) together. The cost function updates parameters in both networks simultaneously.\n",
    "\n",
    "### Example Code Snippet (Conceptual)\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define user network\n",
    "user_input = tf.keras.Input(shape=(user_feature_size,))\n",
    "user_net = layers.Dense(128, activation='relu')(user_input)\n",
    "user_net = layers.Dense(64, activation='relu')(user_net)\n",
    "v_u = layers.Dense(32)(user_net)\n",
    "v_u = layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))(v_u)\n",
    "\n",
    "# Define movie network\n",
    "movie_input = tf.keras.Input(shape=(movie_feature_size,))\n",
    "movie_net = layers.Dense(64, activation='relu')(movie_input)\n",
    "movie_net = layers.Dense(32, activation='relu')(movie_net)\n",
    "v_m = layers.Dense(32)(movie_net)\n",
    "v_m = layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))(v_m)\n",
    "\n",
    "# Compute dot product\n",
    "dot_product = layers.Dot(axes=1)([v_u, v_m])\n",
    "\n",
    "# Define the model\n",
    "model = models.Model(inputs=[user_input, movie_input], outputs=dot_product)\n",
    "model.compile(optimizer='adam', loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cb0bf4-c1b3-4104-b98d-741a92c7a84a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
