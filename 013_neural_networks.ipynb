{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6385e496-d2d8-4424-ba09-235b90411e0d",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "## What are Neural Networks?\n",
    "\n",
    "Neural networks are, at their heart, an advanced form of logistic regression that learns hierarchical features, removing the need for manual feature engineering. Instead of manually engineering features (e.g., combining dimensions for house pricing), neural networks learn the best features during training.\n",
    "- Computational models inspired by the human brain.\n",
    "- Consist of interconnected units called *neurons*.\n",
    "- Can automatically learn and extract useful features from raw data.\n",
    "\n",
    "\n",
    "### Network Architecture\n",
    "\n",
    "- **Activation ($a$):** The output of a neuron after applying the activation function (e.g., sigmoid). Reflects how strongly a neuron signals to subsequent layers.\n",
    "- **Input Layer:** The raw input data (the feature vector).\n",
    "- **Hidden Layers**  Intermediate layers where feature extraction occurs.\n",
    "- **Output Layer:** Produces the final prediction.\n",
    "- **Fully Connected Layers:** Each neuron in a layer receives input from every neuron in the previous layer. This design allows the network to automatically learn which features are important.\n",
    "\n",
    "> **Key Concept:** *The hidden layer is called \"hidden\" because its intermediate outputs are not directly observed in the training data.*\n",
    "\n",
    "### Advantages of Neural Networks\n",
    "\n",
    "1. **Automatic Feature Learning:**\n",
    "   - Unlike manual feature engineering, neural networks learn the best representations from the data.\n",
    "   - **Analogy:** Instead of a chef pre-selecting ingredients and recipes, the network experiments with combinations until it finds what makes the dish (prediction) best.\n",
    "2. **Flexibility in Architecture:**\n",
    "   - **Multilayer Perceptron (MLP):** A common type of neural network that uses multiple hidden layers.\n",
    "   - **Design Decisions:**\n",
    "     - Number of hidden layers.\n",
    "     - Number of neurons per layer.\n",
    "   - These choices can significantly affect the performance of the model.\n",
    "\n",
    "---\n",
    "\n",
    "## Example: T-Shirt Demand Prediction (Simplest Case)\n",
    "\n",
    "Suppose we want to predict whether a T-shirt is a top seller (Yes/No) using its price.\n",
    "- **Input Feature:** Price ($x$).\n",
    "- **Computation:** \n",
    "  - The neuron calculates a weighted sum of the input plus a bias.\n",
    "  - Passes the result through a sigmoid activation function to produce an output probability.\n",
    "  \n",
    "**Mathematical Representation:**\n",
    "\n",
    "$$\n",
    "a = \\frac{1}{1 + e^{-(w x + b)}}\n",
    "$$\n",
    "\n",
    "Here, $w$ is the weight, $b$ is the bias, and $a$ (activation) is the output probability.\n",
    "- This logistic regression unit is a simplified model of a biological neuron.\n",
    "- The activation $a$ reflects how strongly the neuron \"fires\" or sends its output.\n",
    "\n",
    "---\n",
    "\n",
    "## Building a Neural Network with Multiple Features\n",
    "\n",
    "Now let's expanded the example above and add more features.\n",
    "- **Input Features:**\n",
    "  - Price\n",
    "  - Shipping Costs\n",
    "  - Marketing Spend\n",
    "  - Material Quality\n",
    "\n",
    "- **Key Factors Influencing Sales:**\n",
    "  1. **Affordability:** A function of price and shipping cost.\n",
    "  2. **Awareness:** Driven primarily by marketing spend.\n",
    "  3. **Perceived Quality:** Influenced by material quality and price (since higher price can imply higher quality).\n",
    "\n",
    "**Input Layer:**\n",
    "- Contains the feature vector: $\\mathbf{x} = [\\text{Price}, \\text{Shipping Cost}, \\text{Marketing}, \\text{Material Quality}]$.\n",
    "  \n",
    "**Hidden Layer** Consists of 3 neurons:\n",
    "- **Neuron 1:** Estimates **Affordability**.\n",
    "- **Neuron 2:** Estimates **Awareness**.\n",
    "- **Neuron 3:** Estimates **Perceived Quality**.\n",
    "\n",
    "> In practice, every neuron in the hidden layer is connected to all inputs. The network learns which inputs are most relevant.\n",
    "\n",
    "**Output Layer:**\n",
    "- Contains 1 neuron.\n",
    "- Takes the 3 activations (affordability, awareness, perceived quality) and computes the final probability that the T-shirt is a top seller.\n",
    "\n",
    "### Diagram of the Network\n",
    "\n",
    "| **Layer**       | **Neurons** | **Description**                                                                          |\n",
    "|-----------------|-------------|------------------------------------------------------------------------------------------|\n",
    "| **Input Layer** | 4           | Features: Price, Shipping Cost, Marketing, Material Quality                              |\n",
    "| **Hidden Layer**| 3           | Intermediate estimates: Affordability, Awareness, Perceived Quality (activations)         |\n",
    "| **Output Layer**| 1           | Final prediction: Probability of being a top seller                                      |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c69108a-b423-4b2b-9fb7-c61b5351ebf7",
   "metadata": {},
   "source": [
    "## Neural Networks in Computer Vision: Face Recognition\n",
    "\n",
    "Suppose we want to train a neural network that takes an input image and outputs the identity of the person in that image.\n",
    "\n",
    "**Image Details:**  \n",
    "- The image is **1000 × 1000 pixels**.\n",
    "- Each pixel is represented by an intensity (brightness) value in the range **0–255**.\n",
    "\n",
    "**Data Representation:**  \n",
    "- The image is a **1000 × 1000 matrix**.\n",
    "- By \"unrolling\" this matrix, you get a **vector of 1,000,000 pixel values**.\n",
    "- The $1000 \\times 1000$ grid of pixels is flattened into a single vector $\\mathbf{x}$ of length **1,000,000**.  \n",
    "- The network processes this long vector to extract relevant features for recognizing the face.\n",
    "\n",
    "\n",
    "### Neural Network Architecture for Face Recognition\n",
    "\n",
    "**Input Layer:** Contains the pixel intensity vector $\\mathbf{x}$ with **1,000,000 elements**.\n",
    "\n",
    "**Hidden Layers:** Each hidden layer progressively extracts more complex features.\n",
    "\n",
    "1. **First Hidden Layer:** Detects low-level features such as edges (e.g., vertical or oriented lines).\n",
    "    - **Window Size:** Small regions of the image.\n",
    "2. **Second Hidden Layer:** Combines edges to detect facial parts like eyes, noses, and ears.\n",
    "    - **Window Size:** Larger regions than the first layer.\n",
    "3. **Third Hidden Layer (if present):** Aggregates facial parts to identify complete face shapes.\n",
    "   - **Window Size:** Even larger regions.\n",
    "  \n",
    "**Output Layer:** Produces the final classification: the identity of the person. Often outputs a probability distribution over possible identities.\n",
    "\n",
    "\n",
    "| **Layer**         | **Role**                                              | **Learned Features**                        |\n",
    "|-------------------|-------------------------------------------------------|---------------------------------------------|\n",
    "| **Input Layer**   | Receives raw pixel intensities                        | N/A                                         |\n",
    "| **1st Hidden Layer** | Extracts basic features                             | Edges and simple lines (e.g., vertical edges) |\n",
    "| **2nd Hidden Layer** | Combines edges into facial parts                   | Facial features (eyes, nose, ear parts)     |\n",
    "| **3rd Hidden Layer** | Aggregates parts into full face shapes (if used)    | Complete facial structure                   |\n",
    "| **Output Layer**  | Classifies the image into a person's identity         | Identity probability (softmax output)       |\n",
    "\n",
    "> **Tip:** The network learns these feature detectors on its own from the data, without explicit programming to look for edges, eyes, or face shapes.\n",
    "  \n",
    "> **Analogy:** Think of the network as a detective who starts by noticing small clues (edges), then pieces together these clues (facial parts), and finally identifies the whole picture (the face).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b142488c-6f74-4749-95f9-588cb61b8fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
