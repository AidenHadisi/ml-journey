{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "## Classification\n",
    "- **Definition:** Predicting a discrete category rather than a continuous value.\n",
    "- **Examples:**\n",
    "  - **Spam detection:** Is an email spam? (**Yes/No**)\n",
    "  - **Fraud detection:** Is a transaction fraudulent? (**Yes/No**)\n",
    "  - **Medical diagnosis:** Is a tumor malignant? (**Yes/No**)\n",
    "\n",
    "\n",
    "### Binary Classification\n",
    "- **Only two possible outcomes:** \n",
    "  - **0 (Negative class)** → Absence of a property  \n",
    "  - **1 (Positive class)** → Presence of a property  \n",
    "\n",
    "\n",
    "### Logistic Regression\n",
    "\n",
    "**Logistic Regression** is one of the most widely used classification algorithms. It is often applied in medical diagnostics, spam detection, and online advertising. Unlike linear regression, logistic regression predicts a probability value and maps it to discrete class labels (0 or 1).  \n",
    "\n",
    "- **Linear regression:** Predicts continuous values.\n",
    "- **Logistic regression:** Predicts probabilities.\n",
    "- **Despite its name, Logistic Regression is used for Classification.**  \n",
    "- **Output:** Probability of the input data belonging to a certain category.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Function\n",
    "\n",
    "The **Sigmoid Function** is used in Logistic Regression to map predictions to probabilities. It is an S-shaped curve that maps any real value to the range [0, 1]. The function is defined as:\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $z$ is the input to the function. A linear combination of the input features.\n",
    "- $\\sigma(z)$ is the output, which is the probability of the input data belonging to the positive class.\n",
    "\n",
    "### 📉 Properties of Sigmoid  \n",
    "| **Value of $z$**  | **$\\sigma(z)$ Output** |\n",
    "|--------------------|----------------|\n",
    "| $z \\to +\\infty$  | $\\sigma(z) \\to 1$  |\n",
    "| $z = 0$  | $\\sigma(z) = 0.5$ |\n",
    "| $z \\to -\\infty$  | $\\sigma(z) \\to 0$  |\n",
    "\n",
    "The sigmoid function **compresses** any input $z$ into a probability range of **(0,1)**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model\n",
    "\n",
    "The Logistic Regression model follows a 2-step process:\n",
    "1. **Linear Combination:** Compute the linear combination of the input features and weights.\n",
    "\n",
    "$$\n",
    "z = w \\cdot x + b\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "2. **Sigmoid Activation:** Apply the sigmoid function to the linear combination to get the probability.\n",
    "\n",
    "$$\n",
    "f(x) = \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "Therefore, the Logistic Regression model can be represented as:\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{1 + e^{-(w \\cdot x + b)}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $f(x)$ is the predicted probability of the input data belonging to the positive class.\n",
    "- $w$ is the weight vector.\n",
    "- $x$ is the input feature vector.\n",
    "- $b$ is the bias term.\n",
    "\n",
    "The output of logistic regression, $f(x)$, represents the **probability** of a class label being **1**:  \n",
    "$$\n",
    "P(y = 1 \\mid x) = f(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Decision: Choosing $\\hat{y}$\n",
    "\n",
    "To convert the probability into a class label, we apply a **threshold**:\n",
    "\n",
    "$$\n",
    "\\hat{y} =\n",
    "\\begin{cases} \n",
    "1 & \\text{if } f(x) \\geq 0.5 \\\\\n",
    "0 & \\text{if } f(x) < 0.5\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "- If $f(x) \\geq 0.5$, predict **$y = 1$**.\n",
    "- If $f(x) < 0.5$, predict **$y = 0$**.\n",
    "\n",
    "This thresholding mechanism allows logistic regression to separate data into distinct classes.\n",
    "\n",
    "## Decision Boundary\n",
    "\n",
    "The decision boundary is the line that separates the classes in a classification problem. In Logistic Regression. It is the region where the model is **equally confident** about classifying a point as either class 0 or class 1.\n",
    "\n",
    "the model predicts **$y = 1$** whenever:\n",
    "\n",
    "$$\n",
    "w \\cdot x + b \\geq 0\n",
    "$$\n",
    "\n",
    "and **$y = 0$** whenever:\n",
    "\n",
    "$$\n",
    "w \\cdot x + b < 0\n",
    "$$\n",
    "\n",
    "\n",
    "## 🔍 Example: Visualizing a Linear Decision Boundary\n",
    "\n",
    "Consider a dataset with **two features** ($x_1$, $x_2$). The logistic regression model computes:\n",
    "\n",
    "$$\n",
    "z = w_1 x_1 + w_2 x_2 + b\n",
    "$$\n",
    "\n",
    "If we assume:\n",
    "\n",
    "$$\n",
    "w_1 = 1, \\quad w_2 = 1, \\quad b = -3\n",
    "$$\n",
    "\n",
    "Then, the decision boundary occurs where:\n",
    "\n",
    "$$\n",
    "x_1 + x_2 - 3 = 0\n",
    "$$\n",
    "\n",
    "which simplifies to:\n",
    "\n",
    "$$\n",
    "x_1 + x_2 = 3\n",
    "$$\n",
    "\n",
    "🔹 **Interpretation**:\n",
    "- **Points where** $x_1 + x_2 > 3$ → Predict $y = 1$\n",
    "- **Points where** $x_1 + x_2 < 3$ → Predict $y = 0$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Features\n",
    "\n",
    "In practice, the decision boundary is not always linear. Logistic Regression can be extended to capture non-linear relationships by adding **polynomial features**. This allows the model to capture more complex patterns in the data.\n",
    "\n",
    "For example, consider a dataset with a single feature $x$. The logistic regression model with polynomial features can be represented as:\n",
    "\n",
    "$$\n",
    "f(x) = \\sigma(w_1 x + w_2 x^2 + w_3 x^3 + b)\n",
    "$$\n",
    "\n",
    "By adding polynomial features, the model can capture non-linear relationships between the input features and the target variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
