{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "176cbf64-1bd8-4533-b594-6791f1ba4519",
   "metadata": {},
   "source": [
    "# Feature Scaling Notes\n",
    "\n",
    "Feature scaling is a critical preprocessing step in machine learning that standardizes the range of independent variables (features) in the data. Many algorithms, particularly those based on distance calculations or gradient descent (e.g., linear regression, k-nearest neighbors, support vector machines), are sensitive to the scale of input data. Without scaling, features with larger ranges might dominate the learning process, leading to biased or inefficient models.\n",
    "\n",
    "Below are the three main methods of feature scaling, along with detailed explanations and examples.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Min-Max Scaling (Normalization)\n",
    "\n",
    "**Overview:**\n",
    "- **Purpose:** Rescale the feature values to a fixed range, typically between 0 and 1.\n",
    "- **Application:** Useful when the data has a known minimum and maximum, or when the algorithm requires a bounded input.\n",
    "- **Intuitive Analogy:** Think of adjusting the brightness on a TV so that the darkest part is black (0) and the brightest is white (1). Everything in between is scaled accordingly.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "X_{\\text{norm}} = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}}\n",
    "$$\n",
    "\n",
    "**Key Components:**\n",
    "- **$X$:** The original feature value.\n",
    "- **$X_{\\text{min}}$:** The minimum value in the feature.\n",
    "- **$X_{\\text{max}}$:** The maximum value in the feature.\n",
    "\n",
    "**Step-by-Step Breakdown:**\n",
    "1. Identify the minimum ($X_{\\text{min}}$) and maximum ($X_{\\text{max}}$) values in the dataset.\n",
    "2. Subtract the minimum value from each data point.\n",
    "3. Divide the result by the range ($X_{\\text{max}} - X_{\\text{min}}$).\n",
    "\n",
    "**Practical Example:**\n",
    "Imagine you have a feature representing ages ranging from 10 to 80. For a person who is 45 years old:\n",
    "\n",
    "$$\n",
    "X_{\\text{norm}} = \\frac{45 - 10}{80 - 10} = \\frac{35}{70} = 0.5\n",
    "$$\n",
    "\n",
    "This converts the age 45 into a normalized value of 0.5.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Standardization (Z-score Normalization)\n",
    "\n",
    "**Overview:**\n",
    "- **Purpose:** Rescale the data so that it has a mean of 0 and a standard deviation of 1.\n",
    "- **Application:** Particularly useful for algorithms that assume data is normally distributed (e.g., logistic regression, neural networks).\n",
    "- **Intuitive Analogy:** Think of standardization like converting different currencies to a single currency using an exchange rate; the conversion aligns the scale of different values.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "X_{\\text{std}} = \\frac{X - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "**Key Components:**\n",
    "- **$X$:** The original feature value.\n",
    "- **$\\mu$:** The mean of the feature.\n",
    "- **$\\sigma$:** The standard deviation of the feature.\n",
    "\n",
    "**Step-by-Step Breakdown:**\n",
    "1. Calculate the mean ($\\mu$) of the feature.\n",
    "2. Compute the standard deviation ($\\sigma$) of the feature.\n",
    "3. Subtract the mean from each feature value.\n",
    "4. Divide by the standard deviation.\n",
    "\n",
    "**Practical Example:**\n",
    "If the mean age is 50 and the standard deviation is 15, then for an age of 65:\n",
    "\n",
    "$$\n",
    "X_{\\text{std}} = \\frac{65 - 50}{15} = \\frac{15}{15} = 1\n",
    "$$\n",
    "\n",
    "This indicates that an age of 65 is 1 standard deviation above the mean.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Mean Normalization\n",
    "\n",
    "**Overview:**\n",
    "- **Purpose:** Adjusts the data so that its mean becomes 0, while also scaling the values based on the range of the feature.\n",
    "- **Application:** Often used when you want the data centered around zero while maintaining a scale of -1 to 1.\n",
    "- **Intuitive Analogy:** Imagine centering a seesaw so that the balance point is at zero, and all the weights are measured relative to the ends of the seesaw.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "X_{\\text{norm}} = \\frac{X - \\mu}{X_{\\text{max}} - X_{\\text{min}}}\n",
    "$$\n",
    "\n",
    "**Key Components:**\n",
    "- **$X$:** The original feature value.\n",
    "- **$\\mu$:** The mean of the feature.\n",
    "- **$X_{\\text{min}}$:** The minimum value of the feature.\n",
    "- **$X_{\\text{max}}$:** The maximum value of the feature.\n",
    "\n",
    "**Step-by-Step Breakdown:**\n",
    "1. Calculate the mean ($\\mu$) of the feature.\n",
    "2. Determine the range by subtracting $X_{\\text{min}}$ from $X_{\\text{max}}$.\n",
    "3. Subtract the mean from each feature value.\n",
    "4. Divide by the range to obtain the normalized value.\n",
    "\n",
    "**Practical Example:**\n",
    "For a feature where the minimum is 20, the maximum is 100, and the mean is 60, for a value of 80:\n",
    "\n",
    "$$\n",
    "X_{\\text{norm}} = \\frac{80 - 60}{100 - 20} = \\frac{20}{80} = 0.25\n",
    "$$\n",
    "\n",
    "This means the value 80 is 25% of the way between the mean and the maximum when scaled by the range.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "- **Feature Scaling** is used to ensure that each feature contributes equally to the model by standardizing their ranges.\n",
    "- **Min-Max Scaling** normalizes data to a fixed range (0 to 1) and is best when the bounds are known.\n",
    "- **Standardization** transforms data to have a mean of 0 and a standard deviation of 1, making it ideal for normally distributed data.\n",
    "- **Mean Normalization** centers the data around 0 and scales it based on the range, useful for certain applications requiring values in a symmetric interval.\n",
    "\n",
    "These methods can be selected based on the requirements of your machine learning algorithm and the distribution of your data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84760156-afc3-4f88-8f81-662877183506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "def normalization(X: NDArray[np.float64]) -> NDArray[np.float64]:\n",
    "    \"\"\"\n",
    "    Normalizes the input features using the simple min-max scaling method.\n",
    "\n",
    "    Args:\n",
    "        X: The input values (independent variables).\n",
    "\n",
    "    Returns:\n",
    "        The normalized input values.\n",
    "    \"\"\"\n",
    "\n",
    "    max_vals = np.max(X, axis=0)\n",
    "    return X / max_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "338f64c8-7970-4145-a040-5c198142a67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardization(X: NDArray[np.float64]) -> NDArray[np.float64]:\n",
    "    \"\"\"\n",
    "    Standardizes the input features using the z-score method.\n",
    "\n",
    "    Args:\n",
    "        X: The input values (independent variables).\n",
    "\n",
    "    Returns:\n",
    "        The standardized input values.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_vals = np.mean(X, axis=0)\n",
    "    std_devs = np.std(X, axis=0)\n",
    "    return (X - mean_vals) / std_devs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eb751f1-3291-4a54-8ae5-b1ba86ba5ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_normalization(X: NDArray[np.float64]) -> NDArray[np.float64]:\n",
    "    \"\"\"\n",
    "    Normalizes the input features using the mean normalization method.\n",
    "\n",
    "    Args:\n",
    "        X: The input values (independent variables).\n",
    "\n",
    "    Returns:\n",
    "        The normalized input values.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_vals = np.mean(X, axis=0)\n",
    "    max_vals = np.max(X, axis=0)\n",
    "    min_vals = np.min(X, axis=0)\n",
    "    return (X - mean_vals) / (max_vals - min_vals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
